name: Incremental Scraping

on:
  schedule:
    - cron: '0 0 * * 0'  # Run every Sunday at midnight
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for running incremental scraping'
        required: true
        default: 'Manual incremental scraping run'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Prepare environment and set permissions
        run: |
          mkdir -p data
          sudo chown -R 1000:1000 .

      - name: Build and start services
        run: |
          docker compose build
          docker compose up -d
          sleep 10 # Aguarda containers iniciarem

      - name: Install dependencies
        run: |
          docker compose exec -T app poetry install

      - name: Initialize database
        run: |
          docker compose exec -T app poetry run python -m letras init
          
      - name: Run incremental scraping
        run: |
          docker compose exec -T app poetry run python -m letras incremental

      - name: Create Release
        id: create_release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            data/*.zip
            data/RELEASE_NOTES.md
          name: Release ${{ github.run_number }} (Incremental)
          body_path: data/RELEASE_NOTES.md
          tag_name: v${{ github.run_number }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Cleanup
        if: always()
        run: docker compose down --volumes